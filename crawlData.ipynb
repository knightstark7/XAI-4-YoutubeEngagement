{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI FOR YOUTUBE ENGAGEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StudentID|Full Name\n",
    "-|-\n",
    "21127050|Tran Nguyen Huan \n",
    "21127240|Nguyen Phat Dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Crawl necessary data `Youtube` from file `Entube.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl features `Title`, `Tags`, and `Thumbnail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"*\"\n",
    "YOUTUBE_API_URL = \"https://www.googleapis.com/youtube/v3/videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_metadata(video_id):\n",
    "    try:\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"id\": video_id,\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "        response = requests.get(YOUTUBE_API_URL, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"items\" in data and len(data[\"items\"]) > 0:\n",
    "            snippet = data[\"items\"][0][\"snippet\"]\n",
    "            return {\n",
    "                \"Title\": snippet[\"title\"],\n",
    "                \"Tags\": snippet.get(\"tags\", []),\n",
    "                \"Thumbnail\": snippet[\"thumbnails\"][\"high\"][\"url\"],\n",
    "            }\n",
    "        else:\n",
    "            print(f\"No data found for video ID: {video_id}\")\n",
    "            return {\"Title\": None, \"Tags\": None, \"Thumbnail\": None}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video ID {video_id}: {e}\")\n",
    "        return {\"Title\": None, \"Tags\": None, \"Thumbnail\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/EnTube.csv\")\n",
    "\n",
    "# video_data = [get_video_metadata(row[\"video_id\"]) for _, row in df.iterrows()]\n",
    "\n",
    "# crawled_df = pd.DataFrame(video_data)\n",
    "# result_df = pd.concat([df, crawled_df], axis=1)\n",
    "# result_df.to_csv(\"entube_with_metadata.csv\", index=False)\n",
    "# print(\"Crawling completed and saved to entube_with_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/EnTube.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl feature `audio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "def download_audios(youtube_urls, output_path='data/audio/'):\n",
    "    \"\"\"\n",
    "    Download and extract audio for a list of YouTube URLs using yt-dlp.\n",
    "\n",
    "    Args:\n",
    "        youtube_urls (list): List of YouTube video URLs to download.\n",
    "        output_path (str): Directory where audio files will be saved. Defaults to 'data/audio/'.\n",
    "    \"\"\"\n",
    "    if not youtube_urls:\n",
    "        print(\"No URLs provided for download.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # yt-dlp options for audio extraction\n",
    "    ydl_opts = {\n",
    "        'outtmpl': os.path.join(output_path, '%(id)s.%(ext)s'),  # Save with video ID as filename\n",
    "        'format': 'bestaudio/best',  # Best quality audio\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'quiet': True,  # Suppress yt-dlp logs\n",
    "        'ignoreerrors': True,  # Skip videos with errors\n",
    "        'retries': 10,  # Retry failed downloads\n",
    "        'fragment-retries': 10,  # Retry failed fragments\n",
    "        'nooverwrites': True,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download(youtube_urls)  # Pass the list of URLs for batch download\n",
    "        print(f\"Batch download completed for {len(youtube_urls)} videos.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to complete batch download: {e}\")\n",
    "\n",
    "\n",
    "def download_audios_from_csv(dataset, output_path='data/audio/'):\n",
    "    \"\"\"\n",
    "    Download audio for all YouTube videos listed in a CSV dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): DataFrame containing video links.\n",
    "        output_path (str): Directory where audio files will be saved. Defaults to 'data/audio/'.\n",
    "    \"\"\"\n",
    "    youtube_urls = dataset['video_link'].dropna().tolist()  # Extract non-null video links\n",
    "    if youtube_urls:\n",
    "        print(f\"Starting batch download for {len(youtube_urls)} videos.\")\n",
    "        download_audios(youtube_urls, output_path)\n",
    "    else:\n",
    "        print(\"No valid video links found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download audio for all videos in the dataset\n",
    "# download_audios_from_csv(df, output_path='/mnt/d/Thesis/Data/Audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl feature `video content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "def download_video_only(youtube_urls, output_path='data/videos/'):\n",
    "    \"\"\"\n",
    "    Download YouTube videos at 480p resolution without audio.\n",
    "\n",
    "    Args:\n",
    "        youtube_urls (list): List of YouTube video URLs to download.\n",
    "        output_path (str): Directory where the videos will be saved. Defaults to 'data/videos/'.\n",
    "    \"\"\"\n",
    "    if not youtube_urls:\n",
    "        print(\"No URLs provided for download.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # yt-dlp options for video-only download\n",
    "    ydl_opts = {\n",
    "        'outtmpl': os.path.join(output_path, '%(id)s.%(ext)s'),  # Save with video ID as filename\n",
    "        'format': 'bestvideo[height<=480]',  # Video-only, capped at 480p\n",
    "        'quiet': True,  # Suppress yt-dlp logs\n",
    "        'ignoreerrors': True,  # Skip videos with errors\n",
    "        'retries': 10,  # Retry failed downloads\n",
    "        'fragment-retries': 10,  # Retry failed fragments\n",
    "        'nooverwrites': True,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download(youtube_urls)  # Pass the list of URLs for batch download\n",
    "        print(f\"Batch download completed for {len(youtube_urls)} videos.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to complete batch download: {e}\")\n",
    "\n",
    "\n",
    "def download_videos_from_csv(dataset, output_path='data/videos/'):\n",
    "    \"\"\"\n",
    "    Download video-only files (no audio) for all YouTube links listed in a CSV dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): DataFrame containing video links.\n",
    "        output_path (str): Directory where videos will be saved. Defaults to 'data/videos/'.\n",
    "    \"\"\"\n",
    "    youtube_urls = dataset['video_link'].dropna().tolist()  # Extract non-null video links\n",
    "    if youtube_urls:\n",
    "        print(f\"Starting batch download for {len(youtube_urls)} videos.\")\n",
    "        download_video_only(youtube_urls, output_path)\n",
    "    else:\n",
    "        print(\"No valid video links found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch download for 23738 videos.\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] D00vn3X7oI8: Private video. Sign in if you've been granted access to this video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    }
   ],
   "source": [
    "download_videos_from_csv(df, output_path='/mnt/d/Thesis/Data/Video')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
