{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save videos\n",
    "TRAIN_VIDEOS_DIR = \"/mnt/d/Thesis/Data/Video/Train\"\n",
    "TEST_VIDEOS_DIR = \"/mnt/d/Thesis/Data/Video/Test\"\n",
    "os.makedirs(TRAIN_VIDEOS_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_VIDEOS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113810, 15640)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/SnapUGC/train_out.txt', sep='\\t') # remember to remove the quotation at line 342 for train_out.txt\n",
    "test_df = pd.read_csv('data/SnapUGC/test_out.txt', sep='\\t')\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Id                object\n",
       " Video_len        float64\n",
       " order of ECR       int64\n",
       " order of NAWP      int64\n",
       " Title             object\n",
       " Description       object\n",
       " Link              object\n",
       " dtype: object,\n",
       " Id                object\n",
       " Video_len        float64\n",
       " order of ECR       int64\n",
       " order of NAWP      int64\n",
       " Title             object\n",
       " Description       object\n",
       " Link              object\n",
       " dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes, test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Video_len</th>\n",
       "      <th>order of ECR</th>\n",
       "      <th>order of NAWP</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Video_len, order of ECR, order of NAWP, Title, Description, Link]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Link'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Video_len</th>\n",
       "      <th>order of ECR</th>\n",
       "      <th>order of NAWP</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Video_len, order of ECR, order of NAWP, Title, Description, Link]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['Link'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from aiohttp import ClientSession, TCPConnector\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Semaphore to limit concurrency\n",
    "semaphore = asyncio.Semaphore(50)  # Adjust concurrency limit as needed\n",
    "\n",
    "# Download a single video with retry, exponential backoff, and persistent connection\n",
    "async def download_video(session: ClientSession, url: str, save_dir: str, name: str, retries=3):\n",
    "    temp_filename = os.path.join(save_dir, f\"{name}.mp4.part\")\n",
    "    final_filename = os.path.join(save_dir, f\"{name}.mp4\")\n",
    "    \n",
    "    if os.path.exists(final_filename):\n",
    "        return None\n",
    "\n",
    "    async with semaphore:  # Enforce concurrency limit\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                async with session.get(url) as response:\n",
    "                    if response.status == 200:\n",
    "                        # Save the video to a temporary file\n",
    "                        with open(temp_filename, \"wb\") as f:\n",
    "                            f.write(await response.read())\n",
    "                        # Rename to final filename\n",
    "                        os.rename(temp_filename, final_filename)\n",
    "                        return None  # Success\n",
    "                    else:\n",
    "                        error_message = f\"Failed to download {url}, status: {response.status}\"\n",
    "                        if attempt < retries - 1:\n",
    "                            await asyncio.sleep(2 ** attempt)  # Exponential backoff\n",
    "                        else:\n",
    "                            return error_message\n",
    "            except Exception as e:\n",
    "                if attempt < retries - 1:\n",
    "                    await asyncio.sleep(2 ** attempt)  # Exponential backoff\n",
    "                else:\n",
    "                    return f\"Error downloading {url}: {e}\"\n",
    "\n",
    "# Validate URLs\n",
    "def is_valid_url(url):\n",
    "    try:\n",
    "        result = urlparse(url)\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Main function to download all videos with a persistent connection\n",
    "async def download_all_videos(urls, ids, save_dir, error_log_file):\n",
    "    # Create a connector for persistent connections\n",
    "    connector = TCPConnector(limit_per_host=50)  # Adjust as needed\n",
    "    async with aiohttp.ClientSession(connector=connector) as session:\n",
    "        tasks = []\n",
    "        for url, id in zip(urls, ids):\n",
    "            if is_valid_url(url):\n",
    "                tasks.append(download_video(session, url, save_dir, id))\n",
    "            else:\n",
    "                print(f\"Invalid URL: {url}\")\n",
    "        # Process tasks with tqdm for progress tracking\n",
    "        with open(error_log_file, \"a\") as log_file:\n",
    "            for task in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Downloading videos\"):\n",
    "                result = await task                \n",
    "                if result:  # Log only errors\n",
    "                    log_file.write(result + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore 404 links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_404_links(log_file):\n",
    "    if not os.path.exists(log_file):\n",
    "        return []\n",
    "    \n",
    "    with open(log_file, 'r') as file:\n",
    "        text = file.read()\n",
    "    pattern = r\"Failed to download (https?://\\S+), status: 404\"\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    # Check if all lines contain \"status: 404\"\n",
    "    if len(matches) != len(text.strip().split(\"\\n\")):\n",
    "        raise ValueError(\"Encountered a line that does not contain 'status: 404'.\")\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = 'data/SnapUGC/train_download_log.txt'\n",
    "test_logs = 'data/SnapUGC/test_download_log.txt'\n",
    "\n",
    "train_fails = get_404_links(train_logs)\n",
    "test_fails = get_404_links(test_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining: 107506 for train, 14785 for test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading videos: 100%|██████████| 107506/107506 [03:42<00:00, 482.39it/s]\n",
      "Downloading videos: 100%|██████████| 14785/14785 [00:29<00:00, 508.11it/s]\n"
     ]
    }
   ],
   "source": [
    "sub_train_df = train_df[~train_df['Link'].isin(train_fails)]\n",
    "sub_test_df = test_df[~test_df['Link'].isin(test_fails)]\n",
    "\n",
    "print(f\"Remaining: {len(sub_train_df)} for train, {len(sub_test_df)} for test\")\n",
    "await download_all_videos(sub_train_df['Link'], sub_train_df['Id'], TRAIN_VIDEOS_DIR, train_logs)\n",
    "await download_all_videos(sub_test_df['Link'], sub_test_df['Id'], TEST_VIDEOS_DIR, test_logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
